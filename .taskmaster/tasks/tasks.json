{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Project Setup and Environment Configuration",
        "description": "Initialize the project with React, Vite, TypeScript, and set up development tools and environment configurations.",
        "details": "Create a new project using Vite with React and TypeScript template:\n```bash\nnpm create vite@latest whisper-mate --template react-ts\ncd whisper-mate\nnpm install\n```\n\nInstall and configure essential development tools:\n```bash\nnpm install -D eslint eslint-plugin-react-hooks @typescript-eslint/eslint-plugin @typescript-eslint/parser prettier eslint-plugin-prettier eslint-config-prettier\n```\n\nCreate configuration files:\n- `.eslintrc.js` - Configure with React and TypeScript rules\n- `.prettierrc` - Set code formatting rules\n- `tsconfig.json` - Ensure strict type checking and modern JS features\n- `.env.development` and `.env.production` - For environment variables\n\nSet up Git repository with proper .gitignore (include .env files except examples).\n\nCreate folder structure:\n```\nsrc/\n  assets/\n  components/\n  hooks/\n  services/\n  types/\n  utils/\n  App.tsx\n  main.tsx\n```\n\nInstall core dependencies:\n```bash\nnpm install react-router-dom@6.16.0 @tanstack/react-query@4.35.3\n```",
        "testStrategy": "Verify project structure and configuration files are correctly set up. Run `npm run dev` to ensure the development server starts without errors. Check TypeScript compilation with `npm run build` to verify no type errors.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 2,
        "title": "UI Framework Integration with Shadcn/ui and Tailwind CSS",
        "description": "Set up Tailwind CSS and integrate Shadcn/ui component library for consistent design system.",
        "details": "Install Tailwind CSS and its dependencies:\n```bash\nnpm install -D tailwindcss@3.3.3 postcss@8.4.30 autoprefixer@10.4.16\nnpx tailwindcss init -p\n```\n\nConfigure Tailwind in `tailwind.config.js`:\n```javascript\nmodule.exports = {\n  darkMode: ['class'],\n  content: ['./index.html', './src/**/*.{js,ts,jsx,tsx}'],\n  theme: {\n    extend: {\n      colors: {\n        // Custom color palette\n        primary: {\n          DEFAULT: '#3b82f6',\n          // Add more shades\n        },\n        // Add secondary, accent colors\n      },\n      keyframes: {\n        // Add custom animations\n      },\n      animation: {\n        // Reference custom keyframes\n      },\n    },\n  },\n  plugins: [],\n}\n```\n\nCreate `src/index.css` with Tailwind directives:\n```css\n@tailwind base;\n@tailwind components;\n@tailwind utilities;\n```\n\nSet up Shadcn/ui:\n```bash\nnpx shadcn-ui@latest init\n```\n\nInstall essential Shadcn components:\n```bash\nnpx shadcn-ui@latest add button card dialog toast input progress\n```\n\nCreate a theme provider component in `src/components/theme-provider.tsx` to handle light/dark mode.\n\nCreate a UI components index file to centralize exports.",
        "testStrategy": "Create a simple test page with all installed components to verify they render correctly. Test responsive behavior using browser dev tools. Verify theme switching functionality works as expected.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 3,
        "title": "Core Layout and Navigation Structure",
        "description": "Implement the main application layout, including header, content area, and navigation components.",
        "details": "Create layout components:\n\n1. Create `src/components/layout/MainLayout.tsx`:\n```tsx\nimport { Outlet } from 'react-router-dom';\nimport Header from './Header';\n\nexport default function MainLayout() {\n  return (\n    <div className=\"min-h-screen flex flex-col bg-background\">\n      <Header />\n      <main className=\"flex-1 container mx-auto py-6 px-4\">\n        <Outlet />\n      </main>\n      <footer className=\"py-4 text-center text-sm text-muted-foreground\">\n        © {new Date().getFullYear()} Whisper Mate\n      </footer>\n    </div>\n  );\n}\n```\n\n2. Create `src/components/layout/Header.tsx` with app logo and navigation.\n\n3. Set up React Router in `src/App.tsx`:\n```tsx\nimport { BrowserRouter, Routes, Route } from 'react-router-dom';\nimport MainLayout from './components/layout/MainLayout';\nimport HomePage from './pages/HomePage';\nimport HistoryPage from './pages/HistoryPage';\nimport { Toaster } from './components/ui/toaster';\nimport { ThemeProvider } from './components/theme-provider';\n\nexport default function App() {\n  return (\n    <ThemeProvider defaultTheme=\"system\" storageKey=\"whisper-mate-theme\">\n      <BrowserRouter>\n        <Routes>\n          <Route path=\"/\" element={<MainLayout />}>\n            <Route index element={<HomePage />} />\n            <Route path=\"history\" element={<HistoryPage />} />\n          </Route>\n        </Routes>\n      </BrowserRouter>\n      <Toaster />\n    </ThemeProvider>\n  );\n}\n```\n\n4. Create placeholder page components:\n- `src/pages/HomePage.tsx` - Main recording interface\n- `src/pages/HistoryPage.tsx` - Transcription history\n\nImplement responsive design with Tailwind's responsive utilities to ensure the layout works on mobile and desktop devices.",
        "testStrategy": "Test navigation between pages to ensure routing works correctly. Verify layout renders correctly on different screen sizes (mobile, tablet, desktop). Check that theme context is properly applied throughout the application.",
        "priority": "high",
        "dependencies": [
          2
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 4,
        "title": "Audio Recording Interface Implementation",
        "description": "Create the audio recording interface with microphone button, recording status indicator, and audio visualization.",
        "details": "Create audio recording components:\n\n1. Install required packages:\n```bash\nnpm install react-use@17.4.0 wavesurfer.js@7.3.1\n```\n\n2. Create `src/hooks/useAudioRecorder.ts` custom hook:\n```tsx\nimport { useState, useRef, useCallback } from 'react';\n\nexport function useAudioRecorder() {\n  const [isRecording, setIsRecording] = useState(false);\n  const [audioDuration, setAudioDuration] = useState(0);\n  const [audioBlob, setAudioBlob] = useState<Blob | null>(null);\n  const mediaRecorderRef = useRef<MediaRecorder | null>(null);\n  const audioChunksRef = useRef<Blob[]>([]);\n  const startTimeRef = useRef<number>(0);\n  const timerRef = useRef<number | null>(null);\n\n  const startRecording = useCallback(async () => {\n    try {\n      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n      const mediaRecorder = new MediaRecorder(stream);\n      mediaRecorderRef.current = mediaRecorder;\n      audioChunksRef.current = [];\n      \n      mediaRecorder.ondataavailable = (event) => {\n        if (event.data.size > 0) {\n          audioChunksRef.current.push(event.data);\n        }\n      };\n      \n      mediaRecorder.onstop = () => {\n        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/wav' });\n        setAudioBlob(audioBlob);\n        stream.getTracks().forEach(track => track.stop());\n      };\n      \n      mediaRecorder.start();\n      startTimeRef.current = Date.now();\n      setIsRecording(true);\n      \n      // Update duration every 100ms\n      timerRef.current = window.setInterval(() => {\n        setAudioDuration((Date.now() - startTimeRef.current) / 1000);\n      }, 100);\n    } catch (error) {\n      console.error('Error accessing microphone:', error);\n    }\n  }, []);\n\n  const stopRecording = useCallback(() => {\n    if (mediaRecorderRef.current && isRecording) {\n      mediaRecorderRef.current.stop();\n      setIsRecording(false);\n      if (timerRef.current) {\n        clearInterval(timerRef.current);\n        timerRef.current = null;\n      }\n    }\n  }, [isRecording]);\n\n  return {\n    isRecording,\n    audioDuration,\n    audioBlob,\n    startRecording,\n    stopRecording\n  };\n}\n```\n\n3. Create `src/components/AudioRecorder.tsx`:\n```tsx\nimport { useEffect, useRef } from 'react';\nimport { Button } from './ui/button';\nimport { Mic, Square } from 'lucide-react';\nimport { useAudioRecorder } from '../hooks/useAudioRecorder';\nimport WaveSurfer from 'wavesurfer.js';\n\ninterface AudioRecorderProps {\n  onRecordingComplete: (blob: Blob, duration: number) => void;\n}\n\nexport default function AudioRecorder({ onRecordingComplete }: AudioRecorderProps) {\n  const { isRecording, audioDuration, audioBlob, startRecording, stopRecording } = useAudioRecorder();\n  const waveformRef = useRef<HTMLDivElement>(null);\n  const wavesurferRef = useRef<WaveSurfer | null>(null);\n  \n  useEffect(() => {\n    if (waveformRef.current && !wavesurferRef.current) {\n      wavesurferRef.current = WaveSurfer.create({\n        container: waveformRef.current,\n        waveColor: 'rgb(59, 130, 246)',\n        progressColor: 'rgb(37, 99, 235)',\n        height: 80,\n        cursorWidth: 0,\n        barWidth: 2,\n        barGap: 3,\n      });\n    }\n    \n    return () => {\n      wavesurferRef.current?.destroy();\n    };\n  }, []);\n  \n  useEffect(() => {\n    if (audioBlob && !isRecording) {\n      onRecordingComplete(audioBlob, audioDuration);\n      \n      // Display recorded audio waveform\n      const audioUrl = URL.createObjectURL(audioBlob);\n      wavesurferRef.current?.load(audioUrl);\n    }\n  }, [audioBlob, isRecording, audioDuration, onRecordingComplete]);\n\n  return (\n    <div className=\"flex flex-col items-center gap-4\">\n      <div className=\"w-full h-20\" ref={waveformRef} />\n      \n      <div className=\"flex items-center gap-2\">\n        <Button\n          size=\"lg\"\n          variant={isRecording ? \"destructive\" : \"default\"}\n          className=\"rounded-full w-16 h-16 flex items-center justify-center\"\n          onClick={isRecording ? stopRecording : startRecording}\n        >\n          {isRecording ? <Square size={24} /> : <Mic size={24} />}\n        </Button>\n        \n        {isRecording && (\n          <div className=\"text-sm font-medium\">\n            Recording: {audioDuration.toFixed(1)}s\n          </div>\n        )}\n      </div>\n    </div>\n  );\n}\n```\n\n4. Implement audio visualization during recording by connecting to the audio stream and updating the waveform in real-time.",
        "testStrategy": "Test microphone access permissions handling. Verify recording starts and stops correctly. Test the audio visualization to ensure it responds to audio input. Verify the recorded audio blob is correctly passed to the parent component.",
        "priority": "high",
        "dependencies": [
          3
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement useAudioRecorder Custom Hook",
            "description": "Create a custom hook to manage audio recording state and functionality",
            "dependencies": [],
            "details": "Implement the useAudioRecorder.ts hook that handles recording state, audio duration tracking, and blob creation. Include state variables for isRecording, audioDuration, and audioBlob. Implement startRecording and stopRecording functions with proper error handling for microphone access permissions.",
            "status": "done",
            "testStrategy": "Test microphone access permissions handling. Verify recording starts and stops correctly. Test timer functionality for duration tracking. Ensure audioBlob is correctly created after recording stops."
          },
          {
            "id": 2,
            "title": "Integrate MediaRecorder API",
            "description": "Implement MediaRecorder API integration for capturing audio from the microphone",
            "dependencies": [
              1
            ],
            "details": "Set up MediaRecorder with the user's audio stream. Configure ondataavailable event to collect audio chunks. Implement onstop event to create the final audio blob. Handle stream cleanup by stopping tracks when recording ends. Implement proper error handling for browser compatibility issues.",
            "status": "done",
            "testStrategy": "Test MediaRecorder initialization with different browser environments. Verify audio chunks are correctly collected during recording. Test blob creation with different audio formats. Ensure resources are properly cleaned up after recording."
          },
          {
            "id": 3,
            "title": "Build Audio Visualization Component with WaveSurfer.js",
            "description": "Create a component for visualizing audio waveforms during and after recording",
            "dependencies": [
              2
            ],
            "details": "Initialize WaveSurfer.js in a React component with appropriate configuration for waveform visualization. Set up the waveform container with proper styling. Implement real-time visualization during recording by connecting to the audio stream. Load recorded audio into WaveSurfer after recording completes. Handle component cleanup to prevent memory leaks.\n<info added on 2025-10-29T14:47:00.019Z>\nSuccessfully integrated WaveSurfer.js visualization component into AudioRecorder.tsx:\n- Implemented WaveSurfer.js initialization with proper configuration parameters for optimal waveform display\n- Created functionality to load recorded audio blobs into WaveSurfer for post-recording waveform visualization\n- Established AudioContext and AnalyserNode setup for real-time audio stream visualization during recording\n- Implemented comprehensive cleanup logic in useEffect return function to properly destroy WaveSurfer instances and disconnect audio nodes when component unmounts\n- Applied responsive styling to waveform container with appropriate height, width, and color schemes that adapt to different screen sizes\n</info added on 2025-10-29T14:47:00.019Z>",
            "status": "done",
            "testStrategy": "Test WaveSurfer initialization with different container sizes. Verify waveform renders correctly for different audio inputs. Test real-time visualization responsiveness. Ensure proper cleanup when component unmounts."
          },
          {
            "id": 4,
            "title": "Create Recording UI Controls",
            "description": "Implement the user interface for recording controls including start/stop button and recording status",
            "dependencies": [
              1,
              3
            ],
            "details": "Create a responsive UI with a microphone button that toggles between recording and stopped states. Implement a recording status indicator showing the current duration. Style the recording button with appropriate colors and icons (Mic for start, Square for stop). Ensure the UI is accessible and provides clear feedback about the current recording state.",
            "status": "done",
            "testStrategy": "Test UI state changes between recording and stopped states. Verify duration display updates correctly. Test accessibility features including keyboard navigation and screen reader compatibility. Test responsive design on different screen sizes."
          },
          {
            "id": 5,
            "title": "Implement Error Handling and Browser Compatibility",
            "description": "Add comprehensive error handling for browser permissions and compatibility issues",
            "dependencies": [
              2,
              4
            ],
            "details": "Implement user-friendly error messages for microphone access denial. Add fallback mechanisms for browsers with limited or no MediaRecorder support. Create a permissions check before attempting to record. Add browser feature detection to warn users about compatibility issues. Implement recovery mechanisms when recording fails unexpectedly.\n<info added on 2025-10-29T14:47:07.167Z>\nError handling and browser compatibility implementation completed:\n- Implemented user-friendly error messages for microphone access denial using Dialog component\n- Added MediaRecorder support detection logic\n- Implemented support for multiple audio formats (webm, wav, ogg)\n- Added browser compatibility checks and fallback mechanisms\n- Created cleanup logic for audio streams when errors occur\n- Added user guidance with troubleshooting steps for common errors including:\n  * Instructions for enabling microphone permissions in browser settings\n  * Suggestions for trying alternative browsers when compatibility issues arise\n  * Steps to resolve common audio recording problems\n  * Browser-specific recommendations for optimal performance\n</info added on 2025-10-29T14:47:07.167Z>",
            "status": "done",
            "testStrategy": "Test behavior when microphone permissions are denied. Verify appropriate messages are displayed for different error scenarios. Test with various browsers to ensure compatibility handling works correctly. Test recovery from unexpected recording failures."
          }
        ]
      },
      {
        "id": 5,
        "title": "OpenAI Whisper API Integration",
        "description": "Implement the service to transcribe audio using OpenAI's Whisper API, including error handling and retry logic.",
        "details": "Create Whisper API integration:\n\n1. Install required packages:\n```bash\nnpm install axios@1.5.0\n```\n\n2. Create environment variables in `.env`:\n```\nVITE_OPENAI_API_KEY=your_api_key\nVITE_WHISPER_API_ENDPOINT=https://api.openai.com/v1/audio/transcriptions\n```\n\n3. Create `src/services/whisperService.ts`:\n```typescript\nimport axios from 'axios';\n\nconst WHISPER_API_ENDPOINT = import.meta.env.VITE_WHISPER_API_ENDPOINT;\nconst OPENAI_API_KEY = import.meta.env.VITE_OPENAI_API_KEY;\n\nconst MAX_RETRIES = 3;\nconst RETRY_DELAY = 1000; // ms\n\ninterface TranscriptionResponse {\n  text: string;\n  language?: string;\n}\n\nexport async function transcribeAudio(audioBlob: Blob): Promise<TranscriptionResponse> {\n  const formData = new FormData();\n  formData.append('file', audioBlob, 'recording.wav');\n  formData.append('model', 'whisper-1');\n  formData.append('response_format', 'json');\n  \n  let attempt = 0;\n  \n  while (attempt < MAX_RETRIES) {\n    try {\n      const response = await axios.post(WHISPER_API_ENDPOINT, formData, {\n        headers: {\n          'Authorization': `Bearer ${OPENAI_API_KEY}`,\n          'Content-Type': 'multipart/form-data',\n        },\n      });\n      \n      return {\n        text: response.data.text,\n        language: response.data.language,\n      };\n    } catch (error) {\n      attempt++;\n      console.error(`Transcription attempt ${attempt} failed:`, error);\n      \n      if (attempt >= MAX_RETRIES) {\n        throw new Error('Failed to transcribe audio after multiple attempts');\n      }\n      \n      // Wait before retrying\n      await new Promise(resolve => setTimeout(resolve, RETRY_DELAY * attempt));\n    }\n  }\n  \n  throw new Error('Failed to transcribe audio');\n}\n```\n\n4. Create a secure proxy for API key handling (optional for production):\n- For development, use the direct API call\n- For production, consider implementing a serverless function to proxy the API call and protect the API key\n\n5. Implement rate limiting awareness:\n```typescript\n// Add to whisperService.ts\nlet lastRequestTime = 0;\nconst MIN_REQUEST_INTERVAL = 200; // ms\n\n// Inside transcribeAudio function\nconst now = Date.now();\nconst timeElapsed = now - lastRequestTime;\nif (timeElapsed < MIN_REQUEST_INTERVAL) {\n  await new Promise(resolve => setTimeout(resolve, MIN_REQUEST_INTERVAL - timeElapsed));\n}\nlastRequestTime = Date.now();\n```",
        "testStrategy": "Create unit tests with mocked API responses. Test successful transcription flow. Test retry logic by simulating API failures. Test handling of various error conditions (network errors, API errors, rate limiting). Verify proper error messages are returned.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 6,
        "title": "Clipboard Integration",
        "description": "Implement clipboard functionality to automatically copy transcribed text and provide user feedback.",
        "details": "Create clipboard integration:\n\n1. Create `src/utils/clipboard.ts`:\n```typescript\nexport async function copyToClipboard(text: string): Promise<boolean> {\n  try {\n    if (navigator.clipboard && window.isSecureContext) {\n      // Use modern Clipboard API\n      await navigator.clipboard.writeText(text);\n      return true;\n    } else {\n      // Fallback for older browsers or non-secure contexts\n      const textArea = document.createElement('textarea');\n      textArea.value = text;\n      textArea.style.position = 'fixed';\n      textArea.style.opacity = '0';\n      document.body.appendChild(textArea);\n      textArea.focus();\n      textArea.select();\n      const result = document.execCommand('copy');\n      document.body.removeChild(textArea);\n      return result;\n    }\n  } catch (error) {\n    console.error('Failed to copy text:', error);\n    return false;\n  }\n}\n```\n\n2. Create `src/hooks/useClipboard.ts`:\n```typescript\nimport { useState } from 'react';\nimport { copyToClipboard } from '../utils/clipboard';\nimport { useToast } from '../components/ui/use-toast';\n\nexport function useClipboard() {\n  const [isCopying, setIsCopying] = useState(false);\n  const { toast } = useToast();\n\n  const copy = async (text: string): Promise<boolean> => {\n    if (!text) return false;\n    \n    setIsCopying(true);\n    try {\n      const success = await copyToClipboard(text);\n      \n      if (success) {\n        toast({\n          title: 'Copied to clipboard',\n          description: 'Text has been copied to your clipboard',\n          duration: 2000,\n        });\n      } else {\n        toast({\n          title: 'Copy failed',\n          description: 'Please try copying manually',\n          variant: 'destructive',\n        });\n      }\n      \n      return success;\n    } finally {\n      setIsCopying(false);\n    }\n  };\n\n  return { copy, isCopying };\n}\n```\n\n3. Create a copy button component in `src/components/CopyButton.tsx`:\n```tsx\nimport { Button } from './ui/button';\nimport { Copy, Check } from 'lucide-react';\nimport { useState } from 'react';\nimport { useClipboard } from '../hooks/useClipboard';\n\ninterface CopyButtonProps {\n  text: string;\n  className?: string;\n}\n\nexport default function CopyButton({ text, className }: CopyButtonProps) {\n  const [copied, setCopied] = useState(false);\n  const { copy, isCopying } = useClipboard();\n\n  const handleCopy = async () => {\n    const success = await copy(text);\n    if (success) {\n      setCopied(true);\n      setTimeout(() => setCopied(false), 2000);\n    }\n  };\n\n  return (\n    <Button\n      variant=\"outline\"\n      size=\"sm\"\n      className={className}\n      onClick={handleCopy}\n      disabled={isCopying || !text}\n    >\n      {copied ? <Check size={16} /> : <Copy size={16} />}\n      <span className=\"ml-2\">{copied ? 'Copied' : 'Copy'}</span>\n    </Button>\n  );\n}\n```\n\n4. Implement automatic clipboard copy after transcription in the main component.",
        "testStrategy": "Test clipboard functionality across different browsers. Test fallback mechanism in non-secure contexts. Verify user feedback (toast notifications) works correctly. Test edge cases like empty text and very large text.",
        "priority": "high",
        "dependencies": [
          3
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "Transcription Result Display and Editing",
        "description": "Create the component to display transcription results with inline editing capability.",
        "details": "Create transcription result components:\n\n1. Create `src/components/TranscriptionResult.tsx`:\n```tsx\nimport { useState, useEffect } from 'react';\nimport { Textarea } from './ui/textarea';\nimport { Button } from './ui/button';\nimport { Card, CardContent, CardFooter } from './ui/card';\nimport CopyButton from './CopyButton';\nimport { useClipboard } from '../hooks/useClipboard';\n\ninterface TranscriptionResultProps {\n  text: string;\n  onTextChange?: (text: string) => void;\n  onSave?: (text: string) => void;\n  isLoading?: boolean;\n}\n\nexport default function TranscriptionResult({\n  text,\n  onTextChange,\n  onSave,\n  isLoading = false,\n}: TranscriptionResultProps) {\n  const [editedText, setEditedText] = useState(text);\n  const [isEditing, setIsEditing] = useState(false);\n  const { copy } = useClipboard();\n  \n  useEffect(() => {\n    setEditedText(text);\n  }, [text]);\n  \n  const handleTextChange = (e: React.ChangeEvent<HTMLTextAreaElement>) => {\n    const newText = e.target.value;\n    setEditedText(newText);\n    onTextChange?.(newText);\n  };\n  \n  const handleSave = () => {\n    setIsEditing(false);\n    onSave?.(editedText);\n    copy(editedText);\n  };\n  \n  return (\n    <Card className=\"w-full\">\n      <CardContent className=\"pt-6\">\n        {isLoading ? (\n          <div className=\"h-32 flex items-center justify-center\">\n            <div className=\"animate-pulse text-muted-foreground\">\n              Transcribing audio...\n            </div>\n          </div>\n        ) : isEditing ? (\n          <Textarea\n            value={editedText}\n            onChange={handleTextChange}\n            className=\"min-h-[120px] resize-y\"\n            placeholder=\"Transcription will appear here\"\n          />\n        ) : (\n          <div className=\"min-h-[120px] p-3 border rounded-md\">\n            {editedText || (\n              <span className=\"text-muted-foreground\">\n                Transcription will appear here\n              </span>\n            )}\n          </div>\n        )}\n      </CardContent>\n      \n      <CardFooter className=\"flex justify-between\">\n        <Button\n          variant=\"outline\"\n          onClick={() => setIsEditing(!isEditing)}\n          disabled={isLoading}\n        >\n          {isEditing ? 'Cancel' : 'Edit'}\n        </Button>\n        \n        {isEditing ? (\n          <Button onClick={handleSave} disabled={!editedText}>\n            Save & Copy\n          </Button>\n        ) : (\n          <CopyButton text={editedText} />\n        )}\n      </CardFooter>\n    </Card>\n  );\n}\n```\n\n2. Integrate the transcription result component with the main page:\n```tsx\n// In HomePage.tsx\nimport { useState } from 'react';\nimport AudioRecorder from '../components/AudioRecorder';\nimport TranscriptionResult from '../components/TranscriptionResult';\nimport { transcribeAudio } from '../services/whisperService';\nimport { useClipboard } from '../hooks/useClipboard';\nimport { useToast } from '../components/ui/use-toast';\n\nexport default function HomePage() {\n  const [transcription, setTranscription] = useState('');\n  const [isTranscribing, setIsTranscribing] = useState(false);\n  const { copy } = useClipboard();\n  const { toast } = useToast();\n  \n  const handleRecordingComplete = async (audioBlob: Blob, duration: number) => {\n    try {\n      setIsTranscribing(true);\n      const result = await transcribeAudio(audioBlob);\n      setTranscription(result.text);\n      \n      // Auto-copy to clipboard\n      if (result.text) {\n        copy(result.text);\n      }\n    } catch (error) {\n      console.error('Transcription failed:', error);\n      toast({\n        title: 'Transcription failed',\n        description: 'There was an error transcribing your audio',\n        variant: 'destructive',\n      });\n    } finally {\n      setIsTranscribing(false);\n    }\n  };\n  \n  return (\n    <div className=\"max-w-2xl mx-auto space-y-8\">\n      <h1 className=\"text-3xl font-bold text-center\">Whisper Mate</h1>\n      \n      <AudioRecorder onRecordingComplete={handleRecordingComplete} />\n      \n      <TranscriptionResult\n        text={transcription}\n        isLoading={isTranscribing}\n        onSave={(text) => setTranscription(text)}\n      />\n    </div>\n  );\n}\n```",
        "testStrategy": "Test rendering of transcription results. Test inline editing functionality. Verify changes are saved correctly. Test auto-copy functionality. Test loading state display during transcription.",
        "priority": "medium",
        "dependencies": [
          4,
          5,
          6
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "Supabase Integration for Data Storage",
        "description": "Set up Supabase for storing transcription history and implement data access services.",
        "details": "Implement Supabase integration:\n\n1. Install Supabase client:\n```bash\nnpm install @supabase/supabase-js@2.33.1\n```\n\n2. Add Supabase environment variables to `.env`:\n```\nVITE_SUPABASE_URL=your_supabase_url\nVITE_SUPABASE_ANON_KEY=your_supabase_anon_key\n```\n\n3. Create Supabase client in `src/services/supabaseClient.ts`:\n```typescript\nimport { createClient } from '@supabase/supabase-js';\n\nconst supabaseUrl = import.meta.env.VITE_SUPABASE_URL;\nconst supabaseAnonKey = import.meta.env.VITE_SUPABASE_ANON_KEY;\n\nif (!supabaseUrl || !supabaseAnonKey) {\n  throw new Error('Missing Supabase environment variables');\n}\n\nexport const supabase = createClient(supabaseUrl, supabaseAnonKey);\n```\n\n4. Create database schema in Supabase:\n```sql\ncreate table public.transcriptions (\n  id uuid default uuid_generate_v4() primary key,\n  created_at timestamp with time zone default now(),\n  text text not null,\n  audio_duration numeric not null,\n  language text\n);\n\n-- Set up RLS policies\nalter table public.transcriptions enable row level security;\n\n-- Allow anonymous access for MVP (consider auth later)\ncreate policy \"Anonymous users can perform all operations\" on public.transcriptions\n  for all using (true);\n```\n\n5. Create transcription service in `src/services/transcriptionService.ts`:\n```typescript\nimport { supabase } from './supabaseClient';\n\nexport interface Transcription {\n  id: string;\n  created_at: string;\n  text: string;\n  audio_duration: number;\n  language?: string;\n}\n\nexport async function saveTranscription(\n  text: string,\n  audioDuration: number,\n  language?: string\n): Promise<Transcription | null> {\n  const { data, error } = await supabase\n    .from('transcriptions')\n    .insert([\n      { text, audio_duration: audioDuration, language },\n    ])\n    .select()\n    .single();\n  \n  if (error) {\n    console.error('Error saving transcription:', error);\n    throw error;\n  }\n  \n  return data;\n}\n\nexport async function getTranscriptions(): Promise<Transcription[]> {\n  const { data, error } = await supabase\n    .from('transcriptions')\n    .select('*')\n    .order('created_at', { ascending: false });\n  \n  if (error) {\n    console.error('Error fetching transcriptions:', error);\n    throw error;\n  }\n  \n  return data || [];\n}\n\nexport async function deleteTranscription(id: string): Promise<void> {\n  const { error } = await supabase\n    .from('transcriptions')\n    .delete()\n    .eq('id', id);\n  \n  if (error) {\n    console.error('Error deleting transcription:', error);\n    throw error;\n  }\n}\n\nexport async function searchTranscriptions(query: string): Promise<Transcription[]> {\n  const { data, error } = await supabase\n    .from('transcriptions')\n    .select('*')\n    .ilike('text', `%${query}%`)\n    .order('created_at', { ascending: false });\n  \n  if (error) {\n    console.error('Error searching transcriptions:', error);\n    throw error;\n  }\n  \n  return data || [];\n}\n```\n\n6. Implement offline support with IndexedDB for local caching (optional):\n```bash\nnpm install idb@7.1.1\n```\n\nCreate a local cache service to sync with Supabase when online.",
        "testStrategy": "Test connection to Supabase. Verify CRUD operations work correctly. Test error handling for network issues. Test search functionality. If implemented, test offline functionality and synchronization.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "Transcription History UI",
        "description": "Create the history page to display, search, and manage past transcriptions.",
        "details": "Implement transcription history UI:\n\n1. Create `src/pages/HistoryPage.tsx`:\n```tsx\nimport { useState, useEffect } from 'react';\nimport { Input } from '../components/ui/input';\nimport { Button } from '../components/ui/button';\nimport { Card, CardContent, CardFooter } from '../components/ui/card';\nimport { Search, Trash2 } from 'lucide-react';\nimport CopyButton from '../components/CopyButton';\nimport { useToast } from '../components/ui/use-toast';\nimport {\n  getTranscriptions,\n  deleteTranscription,\n  searchTranscriptions,\n  Transcription,\n} from '../services/transcriptionService';\n\nexport default function HistoryPage() {\n  const [transcriptions, setTranscriptions] = useState<Transcription[]>([]);\n  const [isLoading, setIsLoading] = useState(true);\n  const [searchQuery, setSearchQuery] = useState('');\n  const { toast } = useToast();\n  \n  const loadTranscriptions = async () => {\n    try {\n      setIsLoading(true);\n      const data = await getTranscriptions();\n      setTranscriptions(data);\n    } catch (error) {\n      console.error('Failed to load transcriptions:', error);\n      toast({\n        title: 'Error loading history',\n        description: 'Could not load your transcription history',\n        variant: 'destructive',\n      });\n    } finally {\n      setIsLoading(false);\n    }\n  };\n  \n  useEffect(() => {\n    loadTranscriptions();\n  }, []);\n  \n  const handleSearch = async () => {\n    if (!searchQuery.trim()) {\n      return loadTranscriptions();\n    }\n    \n    try {\n      setIsLoading(true);\n      const results = await searchTranscriptions(searchQuery);\n      setTranscriptions(results);\n    } catch (error) {\n      console.error('Search failed:', error);\n      toast({\n        title: 'Search failed',\n        description: 'Could not search transcriptions',\n        variant: 'destructive',\n      });\n    } finally {\n      setIsLoading(false);\n    }\n  };\n  \n  const handleDelete = async (id: string) => {\n    try {\n      await deleteTranscription(id);\n      setTranscriptions(prev => prev.filter(t => t.id !== id));\n      toast({\n        title: 'Transcription deleted',\n        description: 'The transcription has been removed from your history',\n      });\n    } catch (error) {\n      console.error('Delete failed:', error);\n      toast({\n        title: 'Delete failed',\n        description: 'Could not delete the transcription',\n        variant: 'destructive',\n      });\n    }\n  };\n  \n  const formatDate = (dateString: string) => {\n    return new Date(dateString).toLocaleString();\n  };\n  \n  return (\n    <div className=\"max-w-4xl mx-auto space-y-6\">\n      <h1 className=\"text-3xl font-bold\">Transcription History</h1>\n      \n      <div className=\"flex gap-2\">\n        <Input\n          placeholder=\"Search transcriptions...\"\n          value={searchQuery}\n          onChange={(e) => setSearchQuery(e.target.value)}\n          onKeyDown={(e) => e.key === 'Enter' && handleSearch()}\n          className=\"flex-1\"\n        />\n        <Button onClick={handleSearch}>\n          <Search size={18} className=\"mr-2\" />\n          Search\n        </Button>\n      </div>\n      \n      {isLoading ? (\n        <div className=\"py-8 text-center text-muted-foreground\">\n          Loading transcriptions...\n        </div>\n      ) : transcriptions.length === 0 ? (\n        <div className=\"py-8 text-center text-muted-foreground\">\n          {searchQuery ? 'No matching transcriptions found' : 'No transcriptions yet'}\n        </div>\n      ) : (\n        <div className=\"space-y-4\">\n          {transcriptions.map((item) => (\n            <Card key={item.id}>\n              <CardContent className=\"pt-6\">\n                <div className=\"text-sm text-muted-foreground mb-2\">\n                  {formatDate(item.created_at)} • {item.audio_duration.toFixed(1)}s\n                  {item.language && ` • ${item.language}`}\n                </div>\n                <div className=\"whitespace-pre-wrap\">{item.text}</div>\n              </CardContent>\n              <CardFooter className=\"flex justify-between\">\n                <Button\n                  variant=\"outline\"\n                  size=\"sm\"\n                  onClick={() => handleDelete(item.id)}\n                >\n                  <Trash2 size={16} className=\"mr-2\" />\n                  Delete\n                </Button>\n                <CopyButton text={item.text} />\n              </CardFooter>\n            </Card>\n          ))}\n        </div>\n      )}\n    </div>\n  );\n}\n```\n\n2. Add pagination for better performance with large history lists:\n```tsx\n// Add to HistoryPage.tsx\nconst ITEMS_PER_PAGE = 10;\nconst [currentPage, setCurrentPage] = useState(1);\n\n// Modify getTranscriptions function to support pagination\nexport async function getTranscriptions(page = 1, perPage = 10): Promise<Transcription[]> {\n  const from = (page - 1) * perPage;\n  const to = from + perPage - 1;\n  \n  const { data, error } = await supabase\n    .from('transcriptions')\n    .select('*')\n    .order('created_at', { ascending: false })\n    .range(from, to);\n  \n  if (error) {\n    console.error('Error fetching transcriptions:', error);\n    throw error;\n  }\n  \n  return data || [];\n}\n\n// Add pagination UI at the bottom of the component\n```\n\n3. Add sorting options (newest first, oldest first, duration).",
        "testStrategy": "Test loading and displaying transcription history. Test search functionality with various queries. Test pagination if implemented. Test sorting options. Test delete functionality. Verify error states are handled correctly.",
        "priority": "medium",
        "dependencies": [
          8
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 10,
        "title": "Error Handling and Monitoring with Sentry",
        "description": "Implement comprehensive error handling throughout the application and integrate Sentry for error tracking.",
        "details": "Set up error handling and Sentry integration:\n\n1. Install Sentry packages:\n```bash\nnpm install @sentry/react@7.69.0 @sentry/tracing@7.69.0\n```\n\n2. Add Sentry environment variables to `.env`:\n```\nVITE_SENTRY_DSN=your_sentry_dsn\nVITE_SENTRY_ENVIRONMENT=development\n```\n\n3. Initialize Sentry in `src/main.tsx`:\n```tsx\nimport React from 'react';\nimport ReactDOM from 'react-dom/client';\nimport * as Sentry from '@sentry/react';\nimport { BrowserTracing } from '@sentry/tracing';\nimport App from './App';\nimport './index.css';\n\nif (import.meta.env.PROD) {\n  Sentry.init({\n    dsn: import.meta.env.VITE_SENTRY_DSN,\n    integrations: [new BrowserTracing()],\n    environment: import.meta.env.VITE_SENTRY_ENVIRONMENT,\n    tracesSampleRate: 0.5,\n  });\n}\n\nReactDOM.createRoot(document.getElementById('root')!).render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>\n);\n```\n\n4. Create error boundary component in `src/components/ErrorBoundary.tsx`:\n```tsx\nimport { Component, ErrorInfo, ReactNode } from 'react';\nimport * as Sentry from '@sentry/react';\nimport { Button } from './ui/button';\n\ninterface Props {\n  children: ReactNode;\n  fallback?: ReactNode;\n}\n\ninterface State {\n  hasError: boolean;\n  error?: Error;\n}\n\nexport class ErrorBoundary extends Component<Props, State> {\n  constructor(props: Props) {\n    super(props);\n    this.state = { hasError: false };\n  }\n\n  static getDerivedStateFromError(error: Error): State {\n    return { hasError: true, error };\n  }\n\n  componentDidCatch(error: Error, errorInfo: ErrorInfo): void {\n    console.error('Uncaught error:', error, errorInfo);\n    Sentry.captureException(error, { extra: errorInfo });\n  }\n\n  render(): ReactNode {\n    if (this.state.hasError) {\n      if (this.props.fallback) {\n        return this.props.fallback;\n      }\n      \n      return (\n        <div className=\"p-6 max-w-md mx-auto mt-10 text-center\">\n          <h2 className=\"text-2xl font-bold mb-4\">Something went wrong</h2>\n          <p className=\"mb-4 text-muted-foreground\">\n            We've been notified about this issue and will work to fix it.\n          </p>\n          <Button\n            onClick={() => window.location.reload()}\n            className=\"mr-2\"\n          >\n            Reload Page\n          </Button>\n          <Button\n            variant=\"outline\"\n            onClick={() => this.setState({ hasError: false })}\n          >\n            Try Again\n          </Button>\n        </div>\n      );\n    }\n\n    return this.props.children;\n  }\n}\n\n// Higher-order component version\nexport const withErrorBoundary = <P extends object>(\n  Component: React.ComponentType<P>,\n  fallback?: ReactNode\n) => {\n  const displayName = Component.displayName || Component.name || 'Component';\n  \n  const WrappedComponent = (props: P) => (\n    <ErrorBoundary fallback={fallback}>\n      <Component {...props} />\n    </ErrorBoundary>\n  );\n  \n  WrappedComponent.displayName = `withErrorBoundary(${displayName})`;\n  \n  return WrappedComponent;\n};\n```\n\n5. Wrap the application with the error boundary in `src/App.tsx`:\n```tsx\nimport { ErrorBoundary } from './components/ErrorBoundary';\n\nexport default function App() {\n  return (\n    <ErrorBoundary>\n      {/* Existing app code */}\n    </ErrorBoundary>\n  );\n}\n```\n\n6. Create a utility for consistent error handling:\n```typescript\n// src/utils/errorHandling.ts\nimport * as Sentry from '@sentry/react';\n\nexport function captureError(error: unknown, context?: Record<string, any>): void {\n  console.error('Application error:', error);\n  \n  if (error instanceof Error) {\n    Sentry.captureException(error, { extra: context });\n  } else {\n    Sentry.captureMessage(String(error), {\n      level: 'error',\n      extra: context,\n    });\n  }\n}\n\nexport function getErrorMessage(error: unknown): string {\n  if (error instanceof Error) return error.message;\n  return String(error);\n}\n```\n\n7. Use the error utilities throughout the application for consistent error handling.",
        "testStrategy": "Test error boundary by intentionally causing errors in components. Verify Sentry captures errors correctly in development mode. Test error recovery mechanisms. Verify user-friendly error messages are displayed.",
        "priority": "medium",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 11,
        "title": "Application State Management",
        "description": "Implement global state management for the application using React Context or a state management library.",
        "details": "Implement application state management:\n\n1. Create a context-based state management system in `src/context/AppContext.tsx`:\n```tsx\nimport { createContext, useContext, useReducer, ReactNode } from 'react';\nimport { Transcription } from '../services/transcriptionService';\n\ninterface AppState {\n  currentTranscription: string;\n  isRecording: boolean;\n  isTranscribing: boolean;\n  recentTranscriptions: Transcription[];\n  darkMode: boolean;\n}\n\ntype AppAction =\n  | { type: 'SET_CURRENT_TRANSCRIPTION'; payload: string }\n  | { type: 'SET_IS_RECORDING'; payload: boolean }\n  | { type: 'SET_IS_TRANSCRIBING'; payload: boolean }\n  | { type: 'ADD_RECENT_TRANSCRIPTION'; payload: Transcription }\n  | { type: 'SET_RECENT_TRANSCRIPTIONS'; payload: Transcription[] }\n  | { type: 'TOGGLE_DARK_MODE' };\n\nconst initialState: AppState = {\n  currentTranscription: '',\n  isRecording: false,\n  isTranscribing: false,\n  recentTranscriptions: [],\n  darkMode: window.matchMedia('(prefers-color-scheme: dark)').matches,\n};\n\nfunction appReducer(state: AppState, action: AppAction): AppState {\n  switch (action.type) {\n    case 'SET_CURRENT_TRANSCRIPTION':\n      return { ...state, currentTranscription: action.payload };\n    case 'SET_IS_RECORDING':\n      return { ...state, isRecording: action.payload };\n    case 'SET_IS_TRANSCRIBING':\n      return { ...state, isTranscribing: action.payload };\n    case 'ADD_RECENT_TRANSCRIPTION':\n      return {\n        ...state,\n        recentTranscriptions: [action.payload, ...state.recentTranscriptions].slice(0, 10),\n      };\n    case 'SET_RECENT_TRANSCRIPTIONS':\n      return { ...state, recentTranscriptions: action.payload };\n    case 'TOGGLE_DARK_MODE':\n      return { ...state, darkMode: !state.darkMode };\n    default:\n      return state;\n  }\n}\n\nconst AppContext = createContext<{\n  state: AppState;\n  dispatch: React.Dispatch<AppAction>;\n}>({ state: initialState, dispatch: () => null });\n\nexport function AppProvider({ children }: { children: ReactNode }) {\n  const [state, dispatch] = useReducer(appReducer, initialState);\n  \n  return (\n    <AppContext.Provider value={{ state, dispatch }}>\n      {children}\n    </AppContext.Provider>\n  );\n}\n\nexport function useAppState() {\n  const context = useContext(AppContext);\n  if (context === undefined) {\n    throw new Error('useAppState must be used within an AppProvider');\n  }\n  return context;\n}\n```\n\n2. Wrap the application with the AppProvider in `src/App.tsx`:\n```tsx\nimport { AppProvider } from './context/AppContext';\n\nexport default function App() {\n  return (\n    <AppProvider>\n      {/* Existing app code */}\n    </AppProvider>\n  );\n}\n```\n\n3. Create custom hooks for specific state slices:\n```tsx\n// src/hooks/useTranscriptionState.ts\nimport { useAppState } from '../context/AppContext';\nimport { Transcription, saveTranscription } from '../services/transcriptionService';\nimport { useClipboard } from './useClipboard';\nimport { useToast } from '../components/ui/use-toast';\nimport { captureError } from '../utils/errorHandling';\n\nexport function useTranscriptionState() {\n  const { state, dispatch } = useAppState();\n  const { copy } = useClipboard();\n  const { toast } = useToast();\n  \n  const setCurrentTranscription = (text: string) => {\n    dispatch({ type: 'SET_CURRENT_TRANSCRIPTION', payload: text });\n  };\n  \n  const setIsRecording = (isRecording: boolean) => {\n    dispatch({ type: 'SET_IS_RECORDING', payload: isRecording });\n  };\n  \n  const setIsTranscribing = (isTranscribing: boolean) => {\n    dispatch({ type: 'SET_IS_TRANSCRIBING', payload: isTranscribing });\n  };\n  \n  const saveAndCopyTranscription = async (\n    text: string,\n    audioDuration: number,\n    language?: string\n  ) => {\n    try {\n      // Save to database\n      const savedTranscription = await saveTranscription(text, audioDuration, language);\n      \n      if (savedTranscription) {\n        dispatch({\n          type: 'ADD_RECENT_TRANSCRIPTION',\n          payload: savedTranscription,\n        });\n      }\n      \n      // Copy to clipboard\n      await copy(text);\n      \n      return savedTranscription;\n    } catch (error) {\n      captureError(error, { context: 'saveAndCopyTranscription' });\n      toast({\n        title: 'Error saving transcription',\n        description: 'Could not save your transcription',\n        variant: 'destructive',\n      });\n      return null;\n    }\n  };\n  \n  return {\n    currentTranscription: state.currentTranscription,\n    isRecording: state.isRecording,\n    isTranscribing: state.isTranscribing,\n    recentTranscriptions: state.recentTranscriptions,\n    setCurrentTranscription,\n    setIsRecording,\n    setIsTranscribing,\n    saveAndCopyTranscription,\n  };\n}\n```\n\n4. Use the custom hooks in components:\n```tsx\n// In HomePage.tsx\nimport { useTranscriptionState } from '../hooks/useTranscriptionState';\n\nexport default function HomePage() {\n  const {\n    currentTranscription,\n    isTranscribing,\n    setCurrentTranscription,\n    setIsTranscribing,\n    saveAndCopyTranscription,\n  } = useTranscriptionState();\n  \n  // Use these state values and functions in the component\n}\n```",
        "testStrategy": "Test state updates through the context. Verify components correctly consume and update the state. Test state persistence if implemented. Test state transitions during the recording and transcription flow.",
        "priority": "medium",
        "dependencies": [
          7,
          8
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 12,
        "title": "End-to-End Testing with Playwright",
        "description": "Set up and implement end-to-end tests for critical user flows using Playwright.",
        "details": "Implement E2E testing with Playwright:\n\n1. Install Playwright:\n```bash\nnpm init playwright@latest\n```\n\n2. Configure Playwright in `playwright.config.ts`:\n```typescript\nimport { defineConfig, devices } from '@playwright/test';\n\nexport default defineConfig({\n  testDir: './tests/e2e',\n  timeout: 30000,\n  fullyParallel: true,\n  forbidOnly: !!process.env.CI,\n  retries: process.env.CI ? 2 : 0,\n  workers: process.env.CI ? 1 : undefined,\n  reporter: 'html',\n  use: {\n    baseURL: 'http://localhost:5173',\n    trace: 'on-first-retry',\n    video: 'on-first-retry',\n  },\n  projects: [\n    { name: 'chromium', use: { ...devices['Desktop Chrome'] } },\n    { name: 'firefox', use: { ...devices['Desktop Firefox'] } },\n    { name: 'webkit', use: { ...devices['Desktop Safari'] } },\n    { name: 'mobile chrome', use: { ...devices['Pixel 5'] } },\n    { name: 'mobile safari', use: { ...devices['iPhone 12'] } },\n  ],\n  webServer: {\n    command: 'npm run dev',\n    port: 5173,\n    reuseExistingServer: !process.env.CI,\n  },\n});\n```\n\n3. Create test fixtures in `tests/e2e/fixtures.ts`:\n```typescript\nimport { test as base } from '@playwright/test';\n\nexport const test = base.extend({\n  // Custom fixtures can be added here\n});\n\nexport { expect } from '@playwright/test';\n```\n\n4. Create a test for the main recording flow in `tests/e2e/recording.spec.ts`:\n```typescript\nimport { test, expect } from './fixtures';\n\ntest.describe('Recording and transcription flow', () => {\n  test('should show recording interface', async ({ page }) => {\n    await page.goto('/');\n    await expect(page.getByRole('heading', { name: 'Whisper Mate' })).toBeVisible();\n    await expect(page.getByRole('button', { name: /mic/i })).toBeVisible();\n  });\n  \n  test('should navigate to history page', async ({ page }) => {\n    await page.goto('/');\n    await page.getByRole('link', { name: /history/i }).click();\n    await expect(page.getByRole('heading', { name: 'Transcription History' })).toBeVisible();\n  });\n  \n  // Mock the recording and transcription process\n  test('should handle the recording flow with mocks', async ({ page }) => {\n    // Mock the MediaRecorder API\n    await page.addInitScript(() => {\n      window.MediaRecorder = class MockMediaRecorder {\n        start() {}\n        stop() {\n          // Simulate the ondataavailable and onstop events\n          setTimeout(() => {\n            this.ondataavailable({ data: new Blob() });\n            this.onstop();\n          }, 500);\n        }\n        ondataavailable: (event: any) => void = () => {};\n        onstop: () => void = () => {};\n      };\n      \n      // Mock getUserMedia\n      navigator.mediaDevices.getUserMedia = async () => {\n        return new MediaStream();\n      };\n    });\n    \n    // Mock the Whisper API response\n    await page.route('**/v1/audio/transcriptions', async (route) => {\n      await route.fulfill({\n        status: 200,\n        contentType: 'application/json',\n        body: JSON.stringify({\n          text: 'This is a mocked transcription result.',\n          language: 'en'\n        }),\n      });\n    });\n    \n    await page.goto('/');\n    \n    // Start recording\n    await page.getByRole('button', { name: /mic/i }).click();\n    \n    // Wait for recording to be active\n    await expect(page.getByText(/recording/i)).toBeVisible();\n    \n    // Stop recording\n    await page.getByRole('button').click();\n    \n    // Wait for transcription result\n    await expect(page.getByText('This is a mocked transcription result.')).toBeVisible();\n  });\n});\n```\n\n5. Create a test for the history page in `tests/e2e/history.spec.ts`:\n```typescript\nimport { test, expect } from './fixtures';\n\ntest.describe('Transcription history', () => {\n  test.beforeEach(async ({ page }) => {\n    // Mock Supabase response for transcriptions\n    await page.route('**/rest/v1/transcriptions**', async (route) => {\n      await route.fulfill({\n        status: 200,\n        contentType: 'application/json',\n        body: JSON.stringify([\n          {\n            id: '1',\n            created_at: new Date().toISOString(),\n            text: 'This is a test transcription.',\n            audio_duration: 5.2,\n            language: 'en'\n          },\n          {\n            id: '2',\n            created_at: new Date(Date.now() - 86400000).toISOString(),\n            text: 'This is an older transcription.',\n            audio_duration: 3.7,\n            language: 'en'\n          }\n        ]),\n      });\n    });\n    \n    await page.goto('/history');\n  });\n  \n  test('should display transcription history', async ({ page }) => {\n    await expect(page.getByText('This is a test transcription.')).toBeVisible();\n    await expect(page.getByText('This is an older transcription.')).toBeVisible();\n  });\n  \n  test('should search transcriptions', async ({ page }) => {\n    // Mock search response\n    await page.route('**/rest/v1/transcriptions**', async (route) => {\n      const url = route.request().url();\n      if (url.includes('ilike')) {\n        await route.fulfill({\n          status: 200,\n          contentType: 'application/json',\n          body: JSON.stringify([\n            {\n              id: '1',\n              created_at: new Date().toISOString(),\n              text: 'This is a test transcription.',\n              audio_duration: 5.2,\n              language: 'en'\n            }\n          ]),\n        });\n      }\n    });\n    \n    await page.getByPlaceholder('Search transcriptions...').fill('test');\n    await page.getByRole('button', { name: 'Search' }).click();\n    \n    await expect(page.getByText('This is a test transcription.')).toBeVisible();\n    await expect(page.getByText('This is an older transcription.')).not.toBeVisible();\n  });\n});\n```\n\n6. Add npm scripts for running tests:\n```json\n// In package.json\n\"scripts\": {\n  \"test\": \"playwright test\",\n  \"test:ui\": \"playwright test --ui\",\n  \"test:headed\": \"playwright test --headed\"\n}\n```",
        "testStrategy": "Run tests in CI/CD pipeline. Test across multiple browsers (Chrome, Firefox, Safari). Test on mobile viewports. Verify tests cover critical user flows: recording, transcription, history management.",
        "priority": "medium",
        "dependencies": [
          7,
          9
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 13,
        "title": "Performance Optimization",
        "description": "Optimize application performance, including code splitting, lazy loading, and resource optimization.",
        "details": "Implement performance optimizations:\n\n1. Configure code splitting and lazy loading in `src/App.tsx`:\n```tsx\nimport { lazy, Suspense } from 'react';\nimport { BrowserRouter, Routes, Route } from 'react-router-dom';\nimport MainLayout from './components/layout/MainLayout';\nimport { Toaster } from './components/ui/toaster';\nimport { ThemeProvider } from './components/theme-provider';\nimport LoadingSpinner from './components/LoadingSpinner';\n\n// Lazy load pages\nconst HomePage = lazy(() => import('./pages/HomePage'));\nconst HistoryPage = lazy(() => import('./pages/HistoryPage'));\n\nexport default function App() {\n  return (\n    <ThemeProvider defaultTheme=\"system\" storageKey=\"whisper-mate-theme\">\n      <BrowserRouter>\n        <Suspense fallback={\n          <div className=\"flex items-center justify-center h-screen\">\n            <LoadingSpinner />\n          </div>\n        }>\n          <Routes>\n            <Route path=\"/\" element={<MainLayout />}>\n              <Route index element={<HomePage />} />\n              <Route path=\"history\" element={<HistoryPage />} />\n            </Route>\n          </Routes>\n        </Suspense>\n      </BrowserRouter>\n      <Toaster />\n    </ThemeProvider>\n  );\n}\n```\n\n2. Optimize audio processing:\n```typescript\n// In useAudioRecorder.ts\n\n// Add audio compression before sending to API\nconst compressAudio = async (blob: Blob): Promise<Blob> => {\n  // For MP3 compression, you would need a library like lamejs\n  // For simple optimization, we can convert to lower quality WAV\n  // This is a placeholder - actual implementation depends on requirements\n  return blob;\n};\n\n// In the stopRecording function\nconst audioBlob = new Blob(audioChunksRef.current, { type: 'audio/wav' });\nconst compressedBlob = await compressAudio(audioBlob);\nsetAudioBlob(compressedBlob);\n```\n\n3. Implement virtualized lists for history page:\n```bash\nnpm install react-window@1.8.9\n```\n\n```tsx\n// In HistoryPage.tsx\nimport { FixedSizeList as List } from 'react-window';\nimport AutoSizer from 'react-virtualized-auto-sizer';\n\n// Replace the transcription list with virtualized list\n<div style={{ height: '70vh' }}>\n  <AutoSizer>\n    {({ height, width }) => (\n      <List\n        height={height}\n        width={width}\n        itemCount={transcriptions.length}\n        itemSize={150}\n      >\n        {({ index, style }) => {\n          const item = transcriptions[index];\n          return (\n            <div style={style}>\n              <Card key={item.id}>\n                {/* Card content */}\n              </Card>\n            </div>\n          );\n        }}\n      </List>\n    )}\n  </AutoSizer>\n</div>\n```\n\n4. Implement memoization for expensive components:\n```tsx\nimport { memo } from 'react';\n\n// Example for TranscriptionResult component\nconst TranscriptionResult = memo(function TranscriptionResult({\n  text,\n  onTextChange,\n  onSave,\n  isLoading = false,\n}: TranscriptionResultProps) {\n  // Component implementation\n});\n```\n\n5. Add image and asset optimization:\n```bash\nnpm install vite-plugin-imagemin -D\n```\n\nConfigure in `vite.config.ts`:\n```typescript\nimport { defineConfig } from 'vite';\nimport react from '@vitejs/plugin-react';\nimport viteImagemin from 'vite-plugin-imagemin';\n\nexport default defineConfig({\n  plugins: [\n    react(),\n    viteImagemin({\n      gifsicle: {\n        optimizationLevel: 7,\n        interlaced: false,\n      },\n      optipng: {\n        optimizationLevel: 7,\n      },\n      mozjpeg: {\n        quality: 80,\n      },\n      pngquant: {\n        quality: [0.8, 0.9],\n        speed: 4,\n      },\n      svgo: {\n        plugins: [\n          {\n            name: 'removeViewBox',\n            active: false,\n          },\n          {\n            name: 'addAttributesToSVGElement',\n            params: {\n              attributes: [{ xmlns: 'http://www.w3.org/2000/svg' }],\n            },\n          },\n        ],\n      },\n    }),\n  ],\n  build: {\n    rollupOptions: {\n      output: {\n        manualChunks: {\n          vendor: ['react', 'react-dom', 'react-router-dom'],\n          ui: ['./src/components/ui'],\n        },\n      },\n    },\n  },\n});\n```\n\n6. Implement service worker for caching and offline support:\n```bash\nnpm install vite-plugin-pwa -D\n```\n\nConfigure in `vite.config.ts`:\n```typescript\nimport { VitePWA } from 'vite-plugin-pwa';\n\nplugins: [\n  // other plugins\n  VitePWA({\n    registerType: 'autoUpdate',\n    includeAssets: ['favicon.ico', 'robots.txt', 'apple-touch-icon.png'],\n    manifest: {\n      name: 'Whisper Mate',\n      short_name: 'WhisperMate',\n      description: 'Voice-to-Text Clipboard App',\n      theme_color: '#ffffff',\n      icons: [\n        // Define icons\n      ],\n    },\n    workbox: {\n      runtimeCaching: [\n        // Cache strategies\n      ],\n    },\n  }),\n],\n```",
        "testStrategy": "Measure and compare performance metrics before and after optimizations using Lighthouse. Test load times for initial page load and navigation between pages. Verify code splitting works by checking network requests. Test memory usage during long recording sessions.",
        "priority": "low",
        "dependencies": [
          7,
          9,
          11
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Code Splitting and Lazy Loading",
            "description": "Configure code splitting and lazy loading for the application to improve initial load time and performance.",
            "dependencies": [],
            "details": "Implement code splitting using React's lazy and Suspense components in src/App.tsx. Configure lazy loading for all page components. Add a loading spinner component to display during chunk loading. Test the implementation by monitoring network requests to verify chunks are loaded on demand.",
            "status": "done",
            "testStrategy": "Measure initial load time before and after implementation using Chrome DevTools. Verify that page components are loaded only when navigated to by monitoring network requests. Test fallback UI appears correctly during loading."
          },
          {
            "id": 2,
            "title": "Optimize Audio Processing and Compression",
            "description": "Implement audio compression and processing optimizations to reduce file size and improve transcription performance.",
            "dependencies": [
              1
            ],
            "details": "Create a compressAudio function in useAudioRecorder.ts to optimize audio before sending to the API. Research and implement appropriate audio compression techniques based on application requirements. Consider using libraries like lamejs for MP3 compression or implementing WebWorkers for background processing to prevent UI blocking.",
            "status": "deferred",
            "testStrategy": "Compare file sizes before and after compression. Measure processing time for audio compression. Test audio quality after compression to ensure it remains suitable for transcription. Verify UI responsiveness during audio processing."
          },
          {
            "id": 3,
            "title": "Implement Virtualized Lists for History Page",
            "description": "Add virtualization to the transcription history list to improve performance with large datasets.",
            "dependencies": [
              1
            ],
            "details": "Install react-window and react-virtualized-auto-sizer packages. Refactor the HistoryPage component to use virtualized lists instead of rendering all items at once. Implement FixedSizeList for rendering only visible items. Configure appropriate item sizes and ensure proper styling of list items within the virtualized container.",
            "status": "done",
            "testStrategy": "Test with large datasets (100+ items) to verify improved rendering performance. Measure memory usage before and after implementation. Verify scroll behavior and item rendering is correct. Test on different screen sizes to ensure responsive behavior."
          },
          {
            "id": 4,
            "title": "Implement Component Memoization",
            "description": "Apply memoization techniques to expensive components to prevent unnecessary re-renders.",
            "dependencies": [
              1
            ],
            "details": "Identify components with expensive rendering operations or components that re-render frequently. Apply React.memo to these components, particularly the TranscriptionResult component. Implement proper dependency arrays for useCallback and useMemo hooks where needed. Review and optimize component props to ensure memoization is effective.",
            "status": "done",
            "testStrategy": "Use React DevTools Profiler to measure render counts before and after memoization. Create test scenarios that would typically cause re-renders and verify memoized components don't re-render unnecessarily. Test application performance under heavy load conditions."
          },
          {
            "id": 5,
            "title": "Set Up Service Worker for Caching and Offline Support",
            "description": "Implement a service worker to enable caching strategies and offline functionality for the application.",
            "dependencies": [
              1
            ],
            "details": "Install vite-plugin-pwa package. Configure the service worker in vite.config.ts with appropriate caching strategies for API responses, static assets, and application shell. Set up the manifest.json file with application metadata and icons. Implement offline fallback pages and notifications for when users are offline. Test caching behavior and offline functionality.",
            "status": "done",
            "testStrategy": "Test application loading in offline mode after initial visit. Verify cached resources are served when offline. Test service worker update process. Measure load time improvements with cached resources. Verify offline indicators and fallbacks appear correctly when network is unavailable."
          }
        ]
      },
      {
        "id": 14,
        "title": "Electron Desktop App Integration",
        "description": "Set up Electron to package the web application as a desktop application for Windows and macOS.",
        "details": "Implement Electron integration:\n\n1. Install Electron and related packages:\n```bash\nnpm install electron@26.2.1 electron-builder@24.6.4 concurrently@8.2.1 wait-on@7.0.1 cross-env@7.0.3 -D\n```\n\n2. Create Electron main process file in `electron/main.js`:\n```javascript\nconst { app, BrowserWindow, ipcMain, clipboard, Tray, Menu, globalShortcut } = require('electron');\nconst path = require('path');\nconst url = require('url');\nconst isDev = process.env.NODE_ENV === 'development';\n\nlet mainWindow;\nlet tray;\n\nfunction createWindow() {\n  mainWindow = new BrowserWindow({\n    width: 1000,\n    height: 800,\n    webPreferences: {\n      nodeIntegration: false,\n      contextIsolation: true,\n      preload: path.join(__dirname, 'preload.js'),\n    },\n    icon: path.join(__dirname, '../public/icon.png'),\n  });\n\n  const startUrl = isDev\n    ? 'http://localhost:5173'\n    : url.format({\n        pathname: path.join(__dirname, '../dist/index.html'),\n        protocol: 'file:',\n        slashes: true,\n      });\n\n  mainWindow.loadURL(startUrl);\n\n  if (isDev) {\n    mainWindow.webContents.openDevTools();\n  }\n\n  mainWindow.on('closed', () => {\n    mainWindow = null;\n  });\n\n  mainWindow.on('minimize', (event) => {\n    event.preventDefault();\n    mainWindow.hide();\n  });\n\n  createTray();\n  registerShortcuts();\n}\n\nfunction createTray() {\n  tray = new Tray(path.join(__dirname, '../public/icon.png'));\n  const contextMenu = Menu.buildFromTemplate([\n    {\n      label: 'Show App',\n      click: () => {\n        if (mainWindow) {\n          mainWindow.show();\n        }\n      },\n    },\n    {\n      label: 'Start Recording',\n      click: () => {\n        if (mainWindow) {\n          mainWindow.webContents.send('start-recording');\n          mainWindow.show();\n        }\n      },\n    },\n    { type: 'separator' },\n    {\n      label: 'Quit',\n      click: () => {\n        app.quit();\n      },\n    },\n  ]);\n\n  tray.setToolTip('Whisper Mate');\n  tray.setContextMenu(contextMenu);\n\n  tray.on('click', () => {\n    if (mainWindow) {\n      mainWindow.isVisible() ? mainWindow.hide() : mainWindow.show();\n    }\n  });\n}\n\nfunction registerShortcuts() {\n  // Global shortcut to start recording\n  globalShortcut.register('CommandOrControl+Shift+R', () => {\n    if (mainWindow) {\n      mainWindow.webContents.send('start-recording');\n      mainWindow.show();\n    }\n  });\n}\n\n// IPC handlers\nipcMain.handle('copy-to-clipboard', (_, text) => {\n  clipboard.writeText(text);\n  return true;\n});\n\napp.whenReady().then(createWindow);\n\napp.on('window-all-closed', () => {\n  if (process.platform !== 'darwin') {\n    app.quit();\n  }\n});\n\napp.on('activate', () => {\n  if (BrowserWindow.getAllWindows().length === 0) {\n    createWindow();\n  }\n});\n\napp.on('will-quit', () => {\n  globalShortcut.unregisterAll();\n});\n```\n\n3. Create preload script in `electron/preload.js`:\n```javascript\nconst { contextBridge, ipcRenderer } = require('electron');\n\ncontextBridge.exposeInMainWorld('electron', {\n  copyToClipboard: (text) => ipcRenderer.invoke('copy-to-clipboard', text),\n});\n\ncontextBridge.exposeInMainWorld('electronAPI', {\n  onStartRecording: (callback) => {\n    ipcRenderer.on('start-recording', callback);\n  },\n});\n```\n\n4. Update `package.json` with Electron scripts:\n```json\n\"scripts\": {\n  \"dev\": \"vite\",\n  \"build\": \"tsc && vite build\",\n  \"electron:dev\": \"concurrently \\\"cross-env NODE_ENV=development vite\\\" \\\"wait-on http://localhost:5173 && electron electron/main.js\\\"\",\n  \"electron:build\": \"npm run build && electron-builder\",\n  \"electron:build:win\": \"npm run build && electron-builder --win\",\n  \"electron:build:mac\": \"npm run build && electron-builder --mac\"\n},\n\"build\": {\n  \"appId\": \"com.whispermate.app\",\n  \"productName\": \"Whisper Mate\",\n  \"files\": [\n    \"dist/**/*\",\n    \"electron/**/*\"\n  ],\n  \"directories\": {\n    \"buildResources\": \"public\",\n    \"output\": \"release\"\n  },\n  \"mac\": {\n    \"category\": \"public.app-category.productivity\",\n    \"target\": [\"dmg\", \"zip\"]\n  },\n  \"win\": {\n    \"target\": [\"nsis\", \"portable\"]\n  },\n  \"linux\": {\n    \"target\": [\"AppImage\", \"deb\"]\n  }\n}\n```\n\n5. Create a utility to detect Electron environment:\n```typescript\n// src/utils/environment.ts\nexport const isElectron = () => {\n  return window.navigator.userAgent.toLowerCase().indexOf('electron') > -1;\n};\n\nexport const getElectronAPI = () => {\n  if (isElectron()) {\n    return (window as any).electron;\n  }\n  return null;\n};\n```\n\n6. Update clipboard utility to use Electron API when available:\n```typescript\n// src/utils/clipboard.ts\nimport { getElectronAPI, isElectron } from './environment';\n\nexport async function copyToClipboard(text: string): Promise<boolean> {\n  try {\n    // Use Electron API if available\n    if (isElectron()) {\n      const electronAPI = getElectronAPI();\n      if (electronAPI?.copyToClipboard) {\n        return await electronAPI.copyToClipboard(text);\n      }\n    }\n    \n    // Web fallback\n    if (navigator.clipboard && window.isSecureContext) {\n      await navigator.clipboard.writeText(text);\n      return true;\n    } else {\n      // Legacy fallback\n      const textArea = document.createElement('textarea');\n      textArea.value = text;\n      textArea.style.position = 'fixed';\n      textArea.style.opacity = '0';\n      document.body.appendChild(textArea);\n      textArea.focus();\n      textArea.select();\n      const result = document.execCommand('copy');\n      document.body.removeChild(textArea);\n      return result;\n    }\n  } catch (error) {\n    console.error('Failed to copy text:', error);\n    return false;\n  }\n}\n```\n\n7. Listen for Electron events in the main component:\n```typescript\n// In HomePage.tsx\nimport { useEffect } from 'react';\nimport { isElectron } from '../utils/environment';\n\nexport default function HomePage() {\n  // Existing code...\n  \n  useEffect(() => {\n    if (isElectron()) {\n      const electronAPI = (window as any).electronAPI;\n      if (electronAPI?.onStartRecording) {\n        const removeListener = electronAPI.onStartRecording(() => {\n          if (!isRecording) {\n            startRecording();\n          }\n        });\n        \n        // Clean up listener\n        return () => removeListener();\n      }\n    }\n  }, [isRecording, startRecording]);\n  \n  // Rest of component...\n}\n```",
        "testStrategy": "Test Electron app on Windows and macOS. Verify system tray functionality. Test global keyboard shortcuts. Verify clipboard integration works in the desktop app. Test app startup and window management. Test auto-updates if implemented.",
        "priority": "low",
        "dependencies": [
          7,
          11,
          13
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Set up Electron Main Process and Window Configuration",
            "description": "Create the main process file and configure the application window settings for the desktop application.",
            "dependencies": [],
            "details": "Create the electron/main.js file with proper window configuration, including size, icon, and loading paths. Implement window event handlers for minimize, close, and activation. Set up development vs production environment detection. Configure proper content security policies and preload script integration. Ensure the application can be properly initialized and displayed.",
            "status": "pending",
            "testStrategy": "Test window creation in both development and production modes. Verify window properties are correctly applied. Test window lifecycle events (minimize, close, reopen). Ensure proper loading of web content in both environments."
          },
          {
            "id": 2,
            "title": "Implement Preload Script for IPC Communication",
            "description": "Create the preload script to enable secure communication between the renderer process and main process.",
            "dependencies": [
              1
            ],
            "details": "Create electron/preload.js to establish secure IPC (Inter-Process Communication) channels. Expose only necessary APIs to the renderer process using contextBridge. Implement clipboard functionality through IPC. Set up event listeners for main-to-renderer communication. Ensure proper context isolation and security practices are followed to prevent potential security vulnerabilities.",
            "status": "pending",
            "testStrategy": "Test all exposed API methods from renderer to main process. Verify context isolation is working correctly. Test event communication from main to renderer process. Ensure no direct Node.js access is available in the renderer process."
          },
          {
            "id": 3,
            "title": "Implement System Tray and Global Shortcuts",
            "description": "Add system tray functionality and global keyboard shortcuts for desktop-specific features.",
            "dependencies": [
              1,
              2
            ],
            "details": "Create system tray implementation with appropriate icon and context menu. Add options for showing the app, starting recording, and quitting. Implement global keyboard shortcuts for starting recording (Ctrl+Shift+R). Ensure proper cleanup of shortcuts when the application quits. Make sure the tray icon and menu are appropriate for both Windows and macOS platforms. Handle platform-specific behaviors for the tray.",
            "status": "pending",
            "testStrategy": "Test tray icon creation and visibility. Verify all context menu items function correctly. Test global shortcuts on both Windows and macOS. Ensure proper cleanup when application quits. Test platform-specific behaviors."
          },
          {
            "id": 4,
            "title": "Adapt Web App for Desktop Environment",
            "description": "Modify the web application to work seamlessly in the Electron desktop environment.",
            "dependencies": [
              2
            ],
            "details": "Create utility functions to detect Electron environment. Update clipboard utility to use Electron's clipboard API when available. Implement listeners for Electron-specific events in React components. Modify UI elements to better fit desktop usage patterns. Update the recording functionality to work with desktop permissions. Ensure the application can respond to system events like sleep/wake and network changes.",
            "status": "pending",
            "testStrategy": "Test environment detection in both web and desktop contexts. Verify clipboard functionality works in both environments. Test UI adaptations for desktop usage. Ensure all features work properly in the desktop environment. Test system event handling."
          },
          {
            "id": 5,
            "title": "Configure Build Process for Multiple Platforms",
            "description": "Set up the build configuration for packaging the application for Windows and macOS.",
            "dependencies": [
              1,
              2,
              3,
              4
            ],
            "details": "Update package.json with Electron build configuration. Configure electron-builder settings for Windows and macOS targets. Set up proper application metadata (appId, productName, etc.). Configure build resources and output directories. Add scripts for development and production builds. Set up platform-specific packaging options (DMG, NSIS, etc.). Ensure proper icon integration for different platforms. Test the build process for both platforms.",
            "status": "pending",
            "testStrategy": "Build the application for Windows and macOS. Test installation packages on both platforms. Verify auto-updates if implemented. Check application icons and metadata. Test startup performance and memory usage. Ensure all packaged resources are correctly included."
          }
        ]
      },
      {
        "id": 15,
        "title": "Deployment and CI/CD Pipeline",
        "description": "Set up continuous integration, deployment pipelines, and release processes for both web and desktop applications.",
        "details": "Implement deployment and CI/CD:\n\n1. Create a GitHub Actions workflow for CI in `.github/workflows/ci.yml`:\n```yaml\nname: CI\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main, develop]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: Setup Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: 18\n          cache: 'npm'\n      - name: Install dependencies\n        run: npm ci\n      - name: Type check\n        run: npm run typecheck\n      - name: Lint\n        run: npm run lint\n      - name: Build\n        run: npm run build\n      - name: Install Playwright browsers\n        run: npx playwright install --with-deps\n      - name: Run Playwright tests\n        run: npm run test\n      - name: Upload test results\n        if: always()\n        uses: actions/upload-artifact@v3\n        with:\n          name: playwright-report\n          path: playwright-report/\n          retention-days: 30\n```\n\n2. Create a deployment workflow for web app in `.github/workflows/deploy-web.yml`:\n```yaml\nname: Deploy Web App\n\non:\n  push:\n    branches: [main]\n    paths-ignore:\n      - 'electron/**'\n      - '**.md'\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: Setup Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: 18\n          cache: 'npm'\n      - name: Install dependencies\n        run: npm ci\n      - name: Build\n        run: npm run build\n        env:\n          VITE_SUPABASE_URL: ${{ secrets.SUPABASE_URL }}\n          VITE_SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}\n          VITE_SENTRY_DSN: ${{ secrets.SENTRY_DSN }}\n          VITE_SENTRY_ENVIRONMENT: 'production'\n      - name: Deploy to Vercel\n        uses: amondnet/vercel-action@v20\n        with:\n          vercel-token: ${{ secrets.VERCEL_TOKEN }}\n          vercel-org-id: ${{ secrets.VERCEL_ORG_ID }}\n          vercel-project-id: ${{ secrets.VERCEL_PROJECT_ID }}\n          vercel-args: '--prod'\n```\n\n3. Create a workflow for building desktop apps in `.github/workflows/build-desktop.yml`:\n```yaml\nname: Build Desktop Apps\n\non:\n  push:\n    tags:\n      - 'v*'\n\njobs:\n  build-windows:\n    runs-on: windows-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: Setup Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: 18\n          cache: 'npm'\n      - name: Install dependencies\n        run: npm ci\n      - name: Build Windows app\n        run: npm run electron:build:win\n        env:\n          VITE_SUPABASE_URL: ${{ secrets.SUPABASE_URL }}\n          VITE_SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}\n          VITE_SENTRY_DSN: ${{ secrets.SENTRY_DSN }}\n          VITE_SENTRY_ENVIRONMENT: 'production'\n      - name: Upload artifacts\n        uses: actions/upload-artifact@v3\n        with:\n          name: windows-app\n          path: release/*.exe\n          retention-days: 5\n\n  build-macos:\n    runs-on: macos-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: Setup Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: 18\n          cache: 'npm'\n      - name: Install dependencies\n        run: npm ci\n      - name: Build macOS app\n        run: npm run electron:build:mac\n        env:\n          VITE_SUPABASE_URL: ${{ secrets.SUPABASE_URL }}\n          VITE_SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}\n          VITE_SENTRY_DSN: ${{ secrets.SENTRY_DSN }}\n          VITE_SENTRY_ENVIRONMENT: 'production'\n      - name: Upload artifacts\n        uses: actions/upload-artifact@v3\n        with:\n          name: macos-app\n          path: release/*.dmg\n          retention-days: 5\n\n  create-release:\n    needs: [build-windows, build-macos]\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: Download all artifacts\n        uses: actions/download-artifact@v3\n      - name: Create Release\n        uses: softprops/action-gh-release@v1\n        with:\n          files: |\n            windows-app/*.exe\n            macos-app/*.dmg\n          draft: false\n          prerelease: false\n          generate_release_notes: true\n```\n\n4. Set up auto-updates for Electron app:\n```bash\nnpm install electron-updater@6.1.4\n```\n\nUpdate `electron/main.js` to include auto-updater:\n```javascript\nconst { autoUpdater } = require('electron-updater');\n\n// In createWindow function\nautoUpdater.checkForUpdatesAndNotify();\n\n// Listen for update events\nautoUpdater.on('update-available', () => {\n  mainWindow.webContents.send('update-available');\n});\n\nautoUpdater.on('update-downloaded', () => {\n  mainWindow.webContents.send('update-downloaded');\n});\n\n// IPC handler for installing updates\nipcMain.on('install-update', () => {\n  autoUpdater.quitAndInstall();\n});\n```\n\n5. Create deployment documentation in `docs/deployment.md` with instructions for:\n- Setting up Vercel for web app deployment\n- Configuring GitHub secrets for CI/CD\n- Manual deployment procedures\n- Release process for desktop apps",
        "testStrategy": "Verify CI pipeline runs successfully on pull requests. Test deployment to staging environment before production. Verify desktop app builds correctly for both Windows and macOS. Test auto-update functionality by releasing a new version.",
        "priority": "low",
        "dependencies": [
          12,
          14
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Set up GitHub Actions for Continuous Integration",
            "description": "Create and configure the CI workflow in GitHub Actions to run tests, type checking, and linting on code changes.",
            "dependencies": [],
            "details": "Create the `.github/workflows/ci.yml` file with configuration for running on push to main/develop branches and pull requests. Configure steps for Node.js setup, dependency installation, type checking, linting, building, and running Playwright tests. Ensure test results are uploaded as artifacts for later review.",
            "status": "pending",
            "testStrategy": "Verify the CI workflow by making a test commit and confirming all checks run successfully. Test with both passing and failing tests to ensure proper reporting. Check that artifacts are correctly uploaded and accessible."
          },
          {
            "id": 2,
            "title": "Implement Web Application Deployment Workflow",
            "description": "Create a GitHub Actions workflow for automatically deploying the web application to Vercel when changes are pushed to the main branch.",
            "dependencies": [
              1
            ],
            "details": "Create the `.github/workflows/deploy-web.yml` file that triggers on pushes to main branch (excluding changes to electron directory and markdown files). Configure the workflow to build the application with production environment variables and deploy to Vercel using the Vercel Action. Set up necessary secrets in GitHub repository settings for Vercel deployment.",
            "status": "pending",
            "testStrategy": "Test the deployment workflow by pushing a minor change to the main branch and verifying successful deployment to Vercel. Confirm that environment variables are correctly passed to the build process. Verify that changes to excluded paths don't trigger deployment."
          },
          {
            "id": 3,
            "title": "Create Desktop Application Build and Release Process",
            "description": "Implement GitHub Actions workflow for building Windows and macOS desktop applications and creating GitHub releases when version tags are pushed.",
            "dependencies": [
              1
            ],
            "details": "Create the `.github/workflows/build-desktop.yml` file that triggers on version tag pushes. Configure separate jobs for Windows and macOS builds using appropriate runners. Set up the build process with environment variables, artifact uploading, and a final job to create GitHub releases with the built executables. Ensure proper versioning and release notes generation.",
            "status": "pending",
            "testStrategy": "Test the release process by creating a test version tag and verifying that Windows and macOS applications are correctly built and included in the GitHub release. Verify that release notes are generated and the artifacts can be downloaded and installed."
          },
          {
            "id": 4,
            "title": "Implement Auto-Update Functionality for Desktop Applications",
            "description": "Add auto-update capability to the Electron desktop application to allow users to receive and install updates automatically.",
            "dependencies": [
              3
            ],
            "details": "Install the electron-updater package and modify the main Electron process to check for updates. Implement event handlers for update-available and update-downloaded events, and create IPC handlers for the renderer process to communicate with the updater. Create documentation in docs/deployment.md covering all deployment processes including Vercel setup, GitHub secrets configuration, and release procedures.",
            "status": "pending",
            "testStrategy": "Test the auto-update functionality by releasing a new version and verifying that existing installations detect and download the update. Test the update notification UI and the installation process. Verify that the application restarts correctly after update installation."
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-10-29T10:27:31.359Z",
      "updated": "2025-10-30T06:56:24.335Z",
      "description": "Tasks for master context"
    }
  }
}